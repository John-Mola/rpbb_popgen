filter(sex == "female")
# CHECKING STUFF ----------------------------------------------------------
df_affinis_historic <- read_csv("./data/data_raw/meta_rpbb_external/rpbb_historic_counties.csv")  %>% clean_names()
v_historic_states <- df_affinis_historic %>% distinct(state) %>% pull(state)
bg_map <- st_as_sf(map("state", regions = v_historic_states, plot = FALSE, fill = TRUE))
p_map <- ggplot() +
geom_sf(data = bg_map, fill = "antiquewhite", alpha = 0.4, color = "grey80", size = 0.4) +
#geom_sf(data = bg_map_extant, fill = "grey", alpha = 0.5, color = "grey80", size = 0.4, aes(text = ID)) +
geom_jitter(data = df_geo_check, aes(x = longitude, y = latitude, fill = lonely), alpha = 0.5, color = "black", shape = 21, size = 2) +
# annotation_scale(location = "bl", width_hint = 0.4) +
# annotation_north_arrow(location = "bl", which_north = "true",
#                        pad_x = unit(0.1, "in"), pad_y = unit(0.3, "in"),
#                        style = north_arrow_fancy_orienteering) +
theme_bw() +
theme(panel.grid.major = element_line(color = gray(0.9),
linetype = "dashed",
size = 0.2),
panel.background = element_rect(fill = "white"),
legend.position = "right")
# labs(x = "", y = "", fill = "Region")
ggplotly(p_map)
##%######################################################%##
#                                                          #
####             SPATIAL DATA CLUSTERING OF             ####
####            POINTS TO ASSIGN POPULATIONS            ####
#                                                          #
##%######################################################%##
#PURPOSE - to take the metadata with lat-long and assign them to clusters based on some threshold rule of distance. This seems preferable to assigning to population based on some more arbitrary metric (like county or just...my decision)
# Things to do in this document
#TODO - ensure specimens have real lat-long and not obscured, if obscured get real and merge
#TODO - plot everything on a map and make sure they are as expected (go back and make corrections as necessary)
#TODO group nearby specimens into "populations" (not sure of the smartest way to do this...)
### Going to try to follow the StackOverflow page here: https://gis.stackexchange.com/questions/17638/clustering-spatial-data-in-r
#TODO - clean this thing up!
# Things to do in the next document
#TODO - merge genotype data with the output of this document
#TODO - add a loci count and other quality check columns as needed
#TODO - ensure output is ready to be converted to required files for COLONY
# PACKAGES ----------------------------------------------------------------
library(tidyverse)
library(sp)
library(sf)
library(maps)
library(rgdal)
library(geosphere)
library(janitor)
library(plotly)
# DATA --------------------------------------------------------------------
df_meta <- readRDS("./data/data_output/df_rpbb_metadata_01b_output.R")
# CONVERT METADATA FRAME INTO A SPATIAL DATA FRAME ------------------------
df_meta2=rename(df_meta, x=longitude,y=latitude) %>%
#TODO - !!!!!!!! NOTE!!!!!!!!! I HAD TO FILTER OUT THE SPECIMENS WITH MISSING LAT-LONG!!!!!!
filter(!is.na(x))
# Transforming mw15 into UTM -----
geo_meta <- st_as_sf(df_meta2, coords = c("x", "y"), crs = 4326)
geo_meta2<-st_transform(x = geo_meta, crs = 32616) # ask Amy about doing these steps
geo_meta2$lon<-st_coordinates(geo_meta2)[,1] # get coordinates
geo_meta2$lat<-st_coordinates(geo_meta2)[,2] # get coordinates
# geo_meta3<-st_set_geometry(geo_meta2, NULL)
# # convert data to a SpatialPointsDataFrame object
# xy <- SpatialPointsDataFrame(
#   matrix(c(x,y), ncol=2), data.frame(ID=seq(1:length(geo_meta))),
#   proj4string=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84"))
# use the distm function to generate a geodesic distance matrix in meters
# mdist <- distm(geo_meta)
mtx_distance <- st_distance(geo_meta, geo_meta)
# cluster all points using a hierarchical clustering approach
hc <- hclust(as.dist(mtx_distance), method="complete")
# define the distance threshold, in this case 40 m
d=30000
# define clusters based on a tree "height" cutoff "d" and add them to the SpDataFrame
geo_meta$cluster <- cutree(hc, h=d)
df_geo <-st_set_geometry(geo_meta, NULL) %>%
inner_join(., df_meta) %>%
group_by(cluster) %>%
add_tally()
df_geo_check <- df_geo %>%
mutate(lonely = if_else(n < 3, "lonely", "grouped")) %>%
filter(sex == "female")
# CHECKING STUFF ----------------------------------------------------------
df_affinis_historic <- read_csv("./data/data_raw/meta_rpbb_external/rpbb_historic_counties.csv")  %>% clean_names()
v_historic_states <- df_affinis_historic %>% distinct(state) %>% pull(state)
bg_map <- st_as_sf(map("state", regions = v_historic_states, plot = FALSE, fill = TRUE))
p_map <- ggplot() +
geom_sf(data = bg_map, fill = "antiquewhite", alpha = 0.4, color = "grey80", size = 0.4) +
#geom_sf(data = bg_map_extant, fill = "grey", alpha = 0.5, color = "grey80", size = 0.4, aes(text = ID)) +
geom_jitter(data = df_geo_check, aes(x = longitude, y = latitude, fill = lonely), alpha = 0.5, color = "black", shape = 21, size = 2) +
# annotation_scale(location = "bl", width_hint = 0.4) +
# annotation_north_arrow(location = "bl", which_north = "true",
#                        pad_x = unit(0.1, "in"), pad_y = unit(0.3, "in"),
#                        style = north_arrow_fancy_orienteering) +
theme_bw() +
theme(panel.grid.major = element_line(color = gray(0.9),
linetype = "dashed",
size = 0.2),
panel.background = element_rect(fill = "white"),
legend.position = "right")
# labs(x = "", y = "", fill = "Region")
ggplotly(p_map)
##%######################################################%##
#                                                          #
####             SPATIAL DATA CLUSTERING OF             ####
####            POINTS TO ASSIGN POPULATIONS            ####
#                                                          #
##%######################################################%##
#PURPOSE - to take the metadata with lat-long and assign them to clusters based on some threshold rule of distance. This seems preferable to assigning to population based on some more arbitrary metric (like county or just...my decision)
# Things to do in this document
#TODO - ensure specimens have real lat-long and not obscured, if obscured get real and merge
#TODO - plot everything on a map and make sure they are as expected (go back and make corrections as necessary)
#TODO group nearby specimens into "populations" (not sure of the smartest way to do this...)
### Going to try to follow the StackOverflow page here: https://gis.stackexchange.com/questions/17638/clustering-spatial-data-in-r
#TODO - clean this thing up!
# Things to do in the next document
#TODO - merge genotype data with the output of this document
#TODO - add a loci count and other quality check columns as needed
#TODO - ensure output is ready to be converted to required files for COLONY
# PACKAGES ----------------------------------------------------------------
library(tidyverse)
library(sp)
library(sf)
library(maps)
library(rgdal)
library(geosphere)
library(janitor)
library(plotly)
# DATA --------------------------------------------------------------------
df_meta <- readRDS("./data/data_output/df_rpbb_metadata_01b_output.R")
# CONVERT METADATA FRAME INTO A SPATIAL DATA FRAME ------------------------
df_meta2=rename(df_meta, x=longitude,y=latitude) %>%
#TODO - !!!!!!!! NOTE!!!!!!!!! I HAD TO FILTER OUT THE SPECIMENS WITH MISSING LAT-LONG!!!!!!
filter(!is.na(x))
# Transforming mw15 into UTM -----
geo_meta <- st_as_sf(df_meta2, coords = c("x", "y"), crs = 4326)
geo_meta2<-st_transform(x = geo_meta, crs = 32616) # ask Amy about doing these steps
geo_meta2$lon<-st_coordinates(geo_meta2)[,1] # get coordinates
geo_meta2$lat<-st_coordinates(geo_meta2)[,2] # get coordinates
# geo_meta3<-st_set_geometry(geo_meta2, NULL)
# # convert data to a SpatialPointsDataFrame object
# xy <- SpatialPointsDataFrame(
#   matrix(c(x,y), ncol=2), data.frame(ID=seq(1:length(geo_meta))),
#   proj4string=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84"))
# use the distm function to generate a geodesic distance matrix in meters
# mdist <- distm(geo_meta)
mtx_distance <- st_distance(geo_meta, geo_meta)
# cluster all points using a hierarchical clustering approach
hc <- hclust(as.dist(mtx_distance), method="complete")
# define the distance threshold, in this case 40 m
d=10000
# define clusters based on a tree "height" cutoff "d" and add them to the SpDataFrame
geo_meta$cluster <- cutree(hc, h=d)
df_geo <-st_set_geometry(geo_meta, NULL) %>%
inner_join(., df_meta) %>%
group_by(cluster) %>%
add_tally()
df_geo_check <- df_geo %>%
mutate(lonely = if_else(n < 3, "lonely", "grouped")) %>%
filter(sex == "female")
# CHECKING STUFF ----------------------------------------------------------
df_affinis_historic <- read_csv("./data/data_raw/meta_rpbb_external/rpbb_historic_counties.csv")  %>% clean_names()
v_historic_states <- df_affinis_historic %>% distinct(state) %>% pull(state)
bg_map <- st_as_sf(map("state", regions = v_historic_states, plot = FALSE, fill = TRUE))
p_map <- ggplot() +
geom_sf(data = bg_map, fill = "antiquewhite", alpha = 0.4, color = "grey80", size = 0.4) +
#geom_sf(data = bg_map_extant, fill = "grey", alpha = 0.5, color = "grey80", size = 0.4, aes(text = ID)) +
geom_jitter(data = df_geo_check, aes(x = longitude, y = latitude, fill = lonely), alpha = 0.5, color = "black", shape = 21, size = 2) +
# annotation_scale(location = "bl", width_hint = 0.4) +
# annotation_north_arrow(location = "bl", which_north = "true",
#                        pad_x = unit(0.1, "in"), pad_y = unit(0.3, "in"),
#                        style = north_arrow_fancy_orienteering) +
theme_bw() +
theme(panel.grid.major = element_line(color = gray(0.9),
linetype = "dashed",
size = 0.2),
panel.background = element_rect(fill = "white"),
legend.position = "right")
# labs(x = "", y = "", fill = "Region")
ggplotly(p_map)
df_geo %>% count(cluster) %>% View
saveRDS(df_geo, "./data/data_output/df_rpbb_clustered_01c_output.Rdata")
## %######################################################%##
#                                                          #
####              WRANGLING AND MERGING OF              ####
####           2020 AND 2021 RPBB COLLECTIONS           ####
#                                                          #
## %######################################################%##
# This document is used to wrange and merge the 2020 and 2021 RPBB genetic collections. Field data and USDA-called genotype data are both loaded in and combined. Some additional helper columns are added and other changes to prepare the data for use in COLONY and downstream analyses.
# Some metadata from 2020 were cleaned using a manual step due to confusion arising from collecting data from several collaborators during a global pandemic...
# Field data from my own collections were also cleaned in a separate step in a prior database. Should the need arise, this file can be provided (but is somewhat unnecessary as we don't have that same cleaning file for other collaborators who submitted data and used a mix of hand and automated cleaning methods)
# Initial tasks
# DONE - which metadata do we want? From USDA or from collectors? What is missing (if anything relevant) from USDA?
#### --> basically only need caste, whether or not it's from a nest, and floral associations. Everything else is redundant. So let's go with whatever the USDA sheet says for all of that.
# Quality checks
# TODO - confirm missing specimens with Jay Watson
# TODO - clean up this document
# Things to do in the next step 01b
# TODO - ensure specimens have real lat-long and not obscured, if obscured get real and merge
# TODO merge with genotype data
# TODO create a "number of loci" column
# TODO - assign all specimens to consistent site names
# TODO group nearby specimens into "populations"...
# PACKAGES ----------------------------------------------------------------
library(tidyverse)
library(readxl)
library(janitor)
library(lubridate)
library(naniar)
`%ni%` <- Negate(`%in%`)
# READ RAW DATA, CLEAN NAMES ----------------------------------------------
# cleaned metadata from 2020 specimens
df_2020_meta <- read_csv("./data/data_output/df_wrangled_2020rpbbMSATs_2021_07_09.csv")
# metadata and genotypes from USDA database
# this was the old call - the new data has a different format with metadata and genotype data on different pages
# df_raw_2021_meta <- read_excel("./metadata/meta_raw/AffinsRepUSDA_Koch_21Dec2021.xlsx", sheet = 2) %>% clean_names()
# maybe for now we just merge metadata with USDA database and make sure all specimens are accounted for...then, we merge the genotype data in later
df_raw_USDA_meta <- read_excel("./data/data_raw/Bombus_affinis_repository__msatdata_ver_22September2022.xlsx", sheet = 1) %>% clean_names()
# USDA data sheet two to help remove metadata that doesn't have any genotype data
df_raw_USDA_2meta <- read_excel("./data/data_raw/Bombus_affinis_repository__msatdata_ver_22September2022.xlsx", sheet = 2) %>% clean_names()
# additional metadata from collectors ----
df_boone <- read_csv("./data/data_raw/from_collectors/boone_raw_data_10-26-2021.csv") %>% clean_names()
df_hepner <- read_excel("./data/data_raw/from_collectors/hepner_raw_data_2021.xlsx") %>% clean_names()
df_watson <- read_excel("./data/data_raw/from_collectors/watson_raw_data_2021.xlsx") %>% clean_names()
df_jean <- read_excel("./data/data_raw/from_collectors/jean_raw_data_2021.xlsx") %>% clean_names()
df_kochanski <- read_excel("./data/data_raw/from_collectors/kochanski_raw_data_2021.xlsx", sheet = 1) %>% clean_names()
df_runquist <- read_excel("./data/data_raw/from_collectors/runquist_raw_data_2021.xlsx", sheet = 1) %>% clean_names()
df_mola <- read_csv("./data/data_output/2021-08-07-rpbb-ISP-JM-tarsi-matched.csv") %>% clean_names()
# REMOVING METADATA WITHOUT GENOTYPES -------------------------------------
# in the USDA sheet2 the specimens that do not have genotypes have a blank "Name" column (some specimens that have a name lack sufficient genotype data but we'll filter that at a later step)
df_has_geno <- df_raw_USDA_2meta %>%
filter(!is.na(name_3))
# need to merge sheet 2 and sheet one by the internal_barcode because I need dates in order to filter out old specimens from the expected metadata
df_modern <- inner_join(df_has_geno, df_raw_USDA_meta, by = c("internal_barcode", "sample_tube_id_with_description")) %>%
mutate(year = year(caught_dd_mmm_yyyy)) %>%
filter(year > 2019)
# CLEANING FIELD COLLECTOR METADATA ---------------------------------------
df_flt_boone <- df_boone %>%
filter(
bombus_species == "affinis",
leg_or_swab == "leg"
) %>%
dplyr::select(unique_id, floral_host, notes) %>%
mutate(
caste = NA_character_,
nest = NA_character_,
id2 = NA_character_
) %>%
dplyr::select(unique_id, id2, caste, nest, floral_host, notes)
df_flt_hepner <- df_hepner %>%
dplyr::select(unique_id, caste, nest, floral_host, notes) %>%
mutate(id2 = NA_character_) %>%
dplyr::select(unique_id, id2, caste, nest, floral_host, notes)
df_flt_jean <- df_jean %>%
dplyr::select(unique_id, caste, nest, floral_host, notes) %>%
mutate(id2 = NA_character_) %>%
dplyr::select(unique_id, id2, caste, nest, floral_host, notes)
df_flt_kochanski <- df_kochanski %>%
dplyr::select(unique_id, caste, nest, floral_host, notes) %>%
mutate(id2 = NA_character_) %>%
dplyr::select(unique_id, id2, caste, nest, floral_host, notes)
df_flt_runquist <- df_runquist %>%
dplyr::select(unique_id, caste, nest, floral_host, notes) %>%
mutate(id2 = NA_character_) %>%
dplyr::select(unique_id, id2, caste, nest, floral_host, notes)
df_flt_watson <- df_watson %>%
dplyr::select(usda_tag, notes) %>%
rename(unique_id = usda_tag) %>%
mutate(
caste = NA_character_,
nest = NA_character_,
id2 = NA_character_,
floral_host = NA_character_
) %>%
dplyr::select(unique_id, id2, caste, nest, floral_host, notes)
df_flt_mola <- df_mola %>%
dplyr::select(un_id, vial_top, caste, nectar_plant, notes) %>%
rename(unique_id = vial_top, id2 = un_id, floral_host = nectar_plant) %>%
mutate(
unique_id = as.character(unique_id),
nest = NA_character_,
id2 = NA_character_
) %>%
dplyr::select(unique_id, id2, caste, nest, floral_host, notes)
df_collectors_mrg <- bind_rows(df_flt_boone, df_flt_hepner, df_flt_jean, df_flt_kochanski, df_flt_mola, df_flt_watson, df_flt_runquist) %>%
mutate(
nest = if_else(floral_host %in% c("nest", "entering nest", "leaving nest"), "nest", nest),
floral_host = if_else(floral_host %in% c("nest", "entering nest", "leaving nest"), NA_character_, floral_host)
) %>%
replace_with_na_all(condition = ~ .x %in% common_na_strings) %>%
# why did I add this "attached" column? Great documentation, John.
mutate(attached = "attached")
# SOME WRANGLING TO 2021 DATA  --------------------------------------------
# TODO - Some values are duplicated. Search for dupes and missing values
# CLEAN - these are the duplicated values, for now I have simply removed all instances as we cannot be sure what is the "true" one or if they came from separate specimens or what:
v_dupes <- c("jmk-12jul21-01", "jmk-12jul21-02")
df_flt_2021_meta <- df_raw_USDA_meta %>%
mutate(year = year(caught_dd_mmm_yyyy)) %>%
inner_join(., df_collectors_mrg, by = c("sample_tube_id_with_description" = "unique_id")) %>%
filter(sample_tube_id_with_description %ni% v_dupes) %>%
rename(
longname = sample_tube_id_with_description,
sex = male_m_female_f_unk,
date = caught_dd_mmm_yyyy,
from_nest = nest,
site = site_description_name
)
# MERGE 2021 WITH 2020 ----------------------------------------------------
# CHECK - this is weird because the 2020 data is entirely from its own metadata file and the 2021 data is from the USDA mostly and then combined with a bit of collector data. Potentially for 2020 we want to pull only the relevant columns (nest, floral associations, notes) and an ID column and then join them....
## --> I think this ends up being fine as this was previously sorted. Just join the barcode for reference.
df_USDA_codes <- df_raw_USDA_meta %>%
select(internal_barcode, sample_tube_id_with_description)
df_partial_2020_meta <- dplyr::select(df_2020_meta, longname, sex, from_nest, which_nest, latitude, longitude, state, county, year, date, site_longname) %>%
rename(site = site_longname) %>%
mutate(floral_host = NA_character_)
df_partial_2021_meta <- df_flt_2021_meta %>%
dplyr::select(longname, sex, from_nest, latitude, longitude, state, county, year, date, site, floral_host) %>%
mutate(
latitude = as.numeric(latitude),
longitude = as.numeric(longitude)
)
# This merge ends up containing missing 10 specimens that are in the USDA database but do not have appropriate metadata. 4 are the duplicates from Jade's collections (with no real way of figuring out exactly where they came from), 1 is an untracked specimen from Elaine (similarly with no real way of knowing whats up), but the remaining five are from Jay. There's a chance some of them are from the known nest...so for now, this seems like an appropriate list.
df_meta_merged <- bind_rows(df_partial_2020_meta, df_partial_2021_meta) %>%
inner_join(., df_USDA_codes, by = c("longname" = "sample_tube_id_with_description")) %>%
filter(year > 2019)
# There were some records with missing lat-long coordinates. I merge them here for simplicity sake.
df_missing_ll <- read_csv("./data/data_raw/from_collectors/df_mlb_missing_coord_fixed.csv") %>%
dplyr::select(sample_tube_id_with_description, latitude, longitude)
df_meta_merged_corrected <- full_join(df_meta_merged, df_missing_ll, by = c("longname" = "sample_tube_id_with_description")) %>%
# this is a dumb way to do it but I'm lazy rn and it works. Not sure how to do the join above in the way I want and not end up with missing/redundant coordinate values
mutate(
latitude = case_when(
!is.na(latitude.x) ~ latitude.x,
is.na(latitude.x) ~ latitude.y,
),
longitude = case_when(
!is.na(longitude.x) ~ longitude.x,
is.na(longitude.x) ~ longitude.y
)
) %>%
dplyr::select(-latitude.x, -longitude.x, -latitude.y, -longitude.y) %>%
# there's one coordinate MLB provided that is missing a USDA barcode (presumably it was not genotyped) so filter that out
filter(!is.na(internal_barcode))
saveRDS(df_meta_merged_corrected, file = "./data/data_output/df_rpbb_metadata_01a_output.Rdata")
##%######################################################%##
#                                                          #
####           SECOND DATA WRANGLING FILE FOR           ####
####     2020/2021 RPBB POPULATION GENETICS PROJECT     ####
#                                                          #
##%######################################################%##
# The purpose of this document is to continue the wrangling of the 2020/2021 RPBB genetic data. Within this document, we ensure consistent naming of sites, states, etc. Originally I planned to do the spatial clustering here, too...but that might be a fraught step so I'll do it in the next script.
# PACKAGES ----------------------------------------------------------------
library(tidyverse)
library(readxl)
library(janitor)
library(lubridate)
library(naniar)
`%ni%` <- Negate(`%in%`)
# DATA --------------------------------------------------------------------
df_meta <- readRDS("./data/data_output/df_rpbb_metadata_01a_output.Rdata")
# VARIOUS NAME STANDARDIZATION --------------------------------------------
# Below, I want to wrangle to ensure consistent naming in sex, state, county, site, and floral_host (i.e. no redundant names or different names for the same thing)
# Consistent SEX labels ---
# For females there is "f", "female", and "worker"
# there are NO gynes in the dataset, so caste is unnecessary
# For males there is "m" "male" and "Male"
# There are 5 NAs for some reason...
#TODO - !!!!!!!!!!!!FOR NOW WE EXCLUDE THE NA SEX INDIVIDUALS!!!!!!!!!!!!!!!
v_males <- c("m", "male", "Male")
v_females <- c("f", "female", "Worker")
# Consistent STATE labels ---
v_wisconsin <- c("WI", "wisconsin")
v_illinois <- c("IL", "Illinois")
v_iowa <- c("IA", "IO", "Iowa")
v_minnesota <- c("minnesota", "Minnesota", "MN")
v_virginia <- c("Virginia")
v_west_virginia <- c("West Virginia", "WV")
# Consistent COUNTY labels ---
# the only issues with counties seem to be capitalization, so I just add that to the wrangling below
# Consistent SITE labels ---
# actually...I'm not sure this really matters and it's kinda a pain. If it matters down the line, I'll do it. But for now, I should probably focus on doing smarter things like measuring the distance between everyone and then clustering them
# Consistent FLORAL_HOST labels
# done below as it's a lot...
# The actual wrangling step; doing it kinda in a redundant way for better readability IMO
df_wrg_meta <- df_meta %>%
# SEX names and filter
mutate(sex = case_when(
sex %in% v_males ~ "male",
sex %in% v_females ~ "female",
sex == "NA" ~ NA_character_
)) %>%
filter(!is.na(sex)) %>%
# STATE names
mutate(state = case_when(
state %in% v_wisconsin ~ "wisconsin",
state %in% v_illinois ~ "illinois",
state %in% v_iowa ~ "iowa",
state %in% v_minnesota ~ "minnesota",
state %in% v_virginia ~ "virginia",
state %in% v_west_virginia ~ "west virginia",
TRUE ~ NA_character_
)) %>%
# COUNTY names
mutate(county = tolower(county)) %>%
mutate(floral_host = case_when(
floral_host == "agastache foeniculum" ~ "Agastache foeniculum",
floral_host == "astilbe" ~ "Astilbe sp.",
floral_host == "Cirsium species" ~ "Cirsium sp.",
floral_host == "Daucus carota" ~ "Daucus carrota",
floral_host == "eutrochium purpureum" ~ "Eurtrochium purpureum",
floral_host == "linaria vulgaris" ~ "Linaria vulgaris",
floral_host == "lotus corniculatus" ~ "Lotus corniculatus",
floral_host == "melilotus albus" ~ "Melilotus albus",
floral_host == "monarda fistulosa" ~ "Monarda fistulosa",
floral_host %in% c("pycanthemum", "Pycnanthemum (virginiana or tenuiflora)", "pycnanthemum virginianum", "Pycnanthemum virginianum") ~ "Pycnanthemum sp.",
floral_host == "Rudbeckia laciniata 'Goldkugel'" ~ "Rudbeckia laciniata",
floral_host == "securigera varia" ~ "Securigera varia",
floral_host == "sorbaria sorbifolia" ~ "Sorbaria sorbifolia",
floral_host == "teucrium canadense" ~ "Teucrium canadense",
floral_host == "thalictrum" ~ "Thalictrum sp.",
floral_host == "Unknown" ~ NA_character_,
floral_host == "vicia americana" ~ "Vicia americana",
floral_host == "in flight" ~ NA_character_,
TRUE ~ floral_host
)) %>%
separate(col = floral_host, into = c("fl_genus", "fl_species"), sep = " ", extra = "merge")
saveRDS(df_wrg_meta, "./data/data_output/df_rpbb_metadata_01b_output.Rdata")
saveRDS(df_geo, "./data/data_output/output_01c_df_rpbb_clustered.Rdata")
saveRDS(df_meta_merged_corrected, file = "./data/data_output/output_01a_df_rpbb_metadata.Rdata")
df_meta <- readRDS("./data/data_output/output_01a_df_rpbb_metadata.Rdata")
saveRDS(df_wrg_meta, "./data/data_output/output_01b_df_rpbb_metadata.Rdata")
df_meta <- readRDS("./data/data_output/output_01b_df_rpbb_metadata.Rdata")
library(tidyverse)
library(janitor)
# Output of 01c, the wrangled metadata assigned to clusters
df_clustered <- readRDS("./data/data_output/output_01c_df_rpbb_clustered.Rdata")
# Output of 01c, the wrangled metadata assigned to clusters
df_clustered <- readRDS("./data/data_output/output_01c_df_rpbb_clustered.Rdata")
library(tidyverse)
library(janitor)
# Output of 01c, the wrangled metadata assigned to clusters
df_clustered <- readRDS("./data/data_output/output_01c_df_rpbb_clustered.Rdata")
df_geno <- readxl::read_xlsx("./data/data_raw/Bombus_affinis_repository__msatdata_ver_22September2022.xlsx", sheet = 2)
df_geno <- readxl::read_xlsx("./data/data_raw/Bombus_affinis_repository__msatdata_ver_22September2022.xlsx", sheet = 2) %>% clean_names()
names(df_geno)
View(df_geno)
df_flt_geno <- df_geno %>%
dplyr::select(-sample_tube_id_with_description, -name_3, -name_18)
View(df_flt_geno)
names(df_clustered)
df_merged <- full_join(df_clustered, df_geno, by = c("internal_barcode"))
View(df_merged)
df_merged <- inner_join(df_clustered, df_flt_geno, by = c("internal_barcode"))
names(df_merged)
df_merged <- inner_join(df_clustered, df_flt_geno, by = c("internal_barcode")) %>%
#just some rearranging of column order for prettiness
dplyr::select(internal_barcode, longname, sex, from_nest, which_nest, state, county, year, date, site, fl_genus, fl_species, cluster, latitude, longitude, n, everything())
saveRDS(df_merged, "./data/data_output/output_01d_merged_genotypes.Rdata")
install.packages("rcolony")
library(tidyverse)
df_rpbb_geno <- readRDS("./data/data_output/output_01d_merged_genotypes.Rdata")
df_rpbb_fulldata <- readRDS("./data/data_output/output_01d_merged_genotypes.Rdata")
names(df_merged)
names(df_flt_geno)
v_loci <- dplyr::select(df_flt_geno, -internal_barcode) %>% names()
v_loci
?gsub
gsub("\\..*","",v_loci)
gsub("\\._*","",v_loci)
gsub("\\_*","",v_loci)
unique(gsub("\\_*","",v_loci))
distinct(gsub("\\_*","",v_loci))
str_remove(v_loci, pattern = "\\_*")
str_remove(v_loci, pattern = "\\._*")
str_remove(v_loci, pattern = "_*")
?str_remove
str_remove(v_loci, pattern = "\\_")
str_remove(v_loci, pattern = "\\_") %>% distinct()
str_remove(v_loci, pattern = "\\_") %>% unique()
str_remove(v_loci, pattern = "\\_*") %>% unique()
distinct(gsub("\\_*","",v_loci)) %>% unique()
gsub("\\_*","",v_loci) %>% unique
gsub("\\_*","",v_loci) %>% unique()
gsub("\\_*","",v_loci)
str_remove(v_loci, pattern = "\\_*") %>% unique()
str_remove(v_loci, pattern = "\\_") %>% unique()
str_remove(v_loci, pattern = "\\_?") %>% unique()
str_remove(v_loci, pattern = "\\__") %>% unique()
str_remove(x, "\\_[^.]*$") %>% unique()
str_remove(v_loci, "\\_[^.]*$") %>% unique()
str_remove(v_loci, "\\_*$") %>% unique()
str_remove(v_loci, "\\_$*") %>% unique()
str_remove(v_loci, "\\_*") %>% unique()
str_remove(v_loci, "\\_[^.]*$") %>% unique()
# Then adding a loci count. Below are two vectors of loci names.
v_loci <- dplyr::select(df_flt_geno, -internal_barcode) %>% names()
#Not sure if we'll need this, but hey.
v_loci_raw <- str_remove(v_loci, "\\_[^.]*$") %>% unique()
df_merged <- inner_join(df_clustered, df_flt_geno, by = c("internal_barcode")) %>%
#just some rearranging of column order for prettiness
dplyr::select(internal_barcode, longname, sex, from_nest, which_nest, state, county, year, date, site, fl_genus, fl_species, cluster, latitude, longitude, n, everything()) %>%
rowwise() %>%
# this is kinda janky because I'm counting values above zero instead of just non-NA values but whatever it works
mutate(loci_w_data = sum(c_across(v_loci) > 0, na.rm = TRUE)/2) %>%
ungroup()
df_merged <- inner_join(df_clustered, df_flt_geno, by = c("internal_barcode")) %>%
#just some rearranging of column order for prettiness
dplyr::select(internal_barcode, longname, sex, from_nest, which_nest, state, county, year, date, site, fl_genus, fl_species, cluster, latitude, longitude, n, everything()) %>%
rowwise() %>%
# this is kinda janky because I'm counting values above zero instead of just non-NA values but whatever it works
mutate(loci_w_data = sum(c_across(all_of(v_loci)) > 0, na.rm = TRUE)/2) %>%
ungroup()
View(df_merged)
saveRDS(df_merged, "./data/data_output/output_01d_merged_genotypes.Rdata")
addinslist:::addinslistAddin()
