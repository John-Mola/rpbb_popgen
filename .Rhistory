#                                                          #
##%######################################################%##
#PURPOSE - to take the metadata with lat-long and assign them to clusters based on some threshold rule of distance. This seems preferable to assigning to population based on some more arbitrary metric (like county or just...my decision)
### This code largely follows the StackOverflow page here: https://gis.stackexchange.com/questions/17638/clustering-spatial-data-in-r
# PACKAGES ----------------------------------------------------------------
library(tidyverse)
library(sp)
library(sf)
library(maps)
library(rgdal)
library(geosphere)
library(janitor)
library(plotly)
# DATA --------------------------------------------------------------------
df_meta <- readRDS("./data/data_output/output_01b_df_rpbb_metadata.Rdata")
# CONVERT METADATA FRAME INTO A SPATIAL DATA FRAME ------------------------
df_meta2=rename(df_meta, x=longitude,y=latitude) %>%
#This next filtering step no longer does anything because there are no longer specimens lacking lat-long data...but I am afraid to change it.
filter(!is.na(x))
# Transforming into UTM -----
geo_meta <- st_as_sf(df_meta2, coords = c("x", "y"), crs = 4326)
geo_meta2<-st_transform(x = geo_meta, crs = 32616)
geo_meta2$lon<-st_coordinates(geo_meta2)[,1] # get coordinates
geo_meta2$lat<-st_coordinates(geo_meta2)[,2] # get coordinates
# use the st_distance function to generate a geodesic distance matrix in meters
mtx_distance <- st_distance(geo_meta2, geo_meta2)
# cluster all points using a hierarchical clustering approach
hc <- hclust(as.dist(mtx_distance), method="complete")
# define multiple distance thresholds
d05 = 5000
d10 = 10000
d25 = 25000
d50 = 50000
d100 = 100000
# define clusters based on a tree "height" cutoff "d" and add them to the SpDataFrame
# geo_meta$cluster <- cutree(hc, h=d)
geo_meta2$cluster05 <- cutree(hc, h=d05)
geo_meta2$cluster10 <- cutree(hc, h=d10)
geo_meta2$cluster25 <- cutree(hc, h=d25)
geo_meta2$cluster50 <- cutree(hc, h=d50)
geo_meta2$cluster100 <- cutree(hc, h=d100)
#changed this to multiple thresholds on 2022-12-15
df_geo <-st_set_geometry(geo_meta2, NULL) %>%
inner_join(., df_meta) %>%
add_count(cluster05, name = "n_cluster05") %>%
add_count(cluster10, name = "n_cluster10") %>%
add_count(cluster25, name = "n_cluster25") %>%
add_count(cluster50, name = "n_cluster50") %>%
add_count(cluster100, name = "n_cluster100")
df_geo_named <- df_geo %>%
mutate(named_cluster100 = case_when(
cluster100 == 1 ~ "Appalachian",
cluster100 == 2 ~ "Iowa City",
cluster100 == 3 ~ "Quad Cities",
cluster100 == 4 ~ "Decorah",
cluster100 == 5 ~ "Twin Cities",
cluster100 == 6 ~ "SE Minnesota",
cluster100 == 7 ~ "Milwaukee",
cluster100 == 8 ~ "Madison",
cluster100 == 9 ~ "North Illinois",
cluster100 == 10 ~ "Chicago",
cluster100 == 11 ~ "North Milwaukee",
cluster100 == 12 ~ "Green Bay",
cluster100 == 13 ~ "Central Wisconsin"
))
# EXPORT RESULT -----------------------------------------------------------
saveRDS(df_geo_named, "./data/data_output/output_01c_df_rpbb_clustered.Rdata")
df_cluster100_centroids <- df_geo_named %>%
group_by(named_cluster100) %>%
summarise(latitude_center = mean(latitude),
longitude_center = mean(longitude),
lat_m_center = mean(lat),
long_m_center = mean(lon))
saveRDS(df_cluster100_centroids, "./data/data_output/output_01c_df_cluster100_centroids.Rdata")
# FINDING CENTROIDS OF SITE (10KM LEVEL) CLUSTERS -------------------------------------------
#note - this will break if colonizer not loaded, done out of order...
df_cluster10_centroids <- df_rpbb_colonizer %>%
group_by(cluster10, year) %>%
summarise(latitude_center = mean(latitude),
longitude_center = mean(longitude),
lat_m_center = mean(lat),
long_m_center = mean(lon),
named_cluster100 = first(named_cluster100),
n = n())
source("./analyses/02c_colonizeR.R")
library(tidyverse)
library(janitor)
# Output of 01c, the wrangled metadata assigned to clusters
df_clustered <- readRDS("./data/data_output/output_01c_df_rpbb_clustered.Rdata")
df_geno <- readxl::read_xlsx("./data/data_raw/Bombus_affinis_repository__msatdata_ver_22September2022.xlsx", sheet = 2) %>% clean_names()
# USDA error rate data
df_err_rates <- readxl::read_xlsx("./data/data_raw/Bombus_affinis_repository__msatdata_ver_22September2022.xlsx", sheet = 3) %>% clean_names() %>% dplyr::select(locus, error_rate)
# Using a threshold of 0.3 (matches USDA sheet recommend)
accepted_error = 0.3
df_good_loci <- df_err_rates %>%
filter(error_rate < accepted_error) %>%
mutate(locus = tolower(locus))
v_good_loci <- df_good_loci %>% pull(locus)
v_good_loci_cols <- df_good_loci %>%
mutate(
loci_1 = paste0(locus, "_1"),
loci_2 = paste0(locus, "_2")
) %>%
select(loci_1, loci_2) %>%
pivot_longer(cols = c(loci_1, loci_2)) %>%
pull(value)
# saving the bad loci column names as that seems cleaner to filter out below
v_bad_loci_cols <- df_err_rates %>%
mutate(locus = tolower(locus)) %>%
filter(error_rate > accepted_error) %>%
mutate(
loci_1 = paste0(locus, "_1"),
loci_2 = paste0(locus, "_2")
) %>%
select(loci_1, loci_2) %>%
pivot_longer(cols = c(loci_1, loci_2)) %>%
pull(value)
df_flt_geno <- df_geno %>%
dplyr::select(-sample_tube_id_with_description, -name_3, -name_18)
df_merged <- inner_join(df_clustered, df_flt_geno, by = c("internal_barcode")) %>%
#just some rearranging of column order for prettiness
dplyr::select(internal_barcode, longname, sex, from_nest, which_nest, state, county, year, date, site, fl_genus, fl_species, cluster05, cluster10, cluster25, cluster50, cluster100, n_cluster05, n_cluster10, n_cluster25, n_cluster50, n_cluster100, named_cluster100, latitude, longitude, everything()) %>%
# REMOVE the bad loci
dplyr::select(-v_bad_loci_cols) %>%
# COUNT the number of loci each individual has
rowwise() %>%
# this is kinda janky because I'm counting values above zero instead of just non-NA values but whatever it works
mutate(loci_w_data = sum(c_across(all_of(v_good_loci_cols)) > 0, na.rm = TRUE)/2) %>%
ungroup()
# Genotype file
saveRDS(df_merged, "./data/data_output/output_01d_merged_genotypes.Rdata")
# Error rates df
saveRDS(df_good_loci, "./data/data_output/output_01d_error_rates.Rdata")
# Error rates vector
saveRDS(v_good_loci_cols, "./data/data_output/output_01d_vector_good_loci.Rdata")
source("./analyses/02c_colonizeR.R")
df_cluster10_centroids <- df_rpbb_colonizer %>%
group_by(cluster10, year) %>%
summarise(latitude_center = mean(latitude),
longitude_center = mean(longitude),
lat_m_center = mean(lat),
long_m_center = mean(lon),
named_cluster100 = first(named_cluster100),
n = n())
saveRDS(df_cluster10_centroids, "./data/data_output/output_01c_df_cluster10_centroids.Rdata")
source("./analyses/02c_colonizeR.R")
df_cluster10_centroids <- df_rpbb_colonizer %>%
group_by(cluster10, year) %>%
summarise(latitude_center = mean(latitude),
longitude_center = mean(longitude),
lat_m_center = mean(lat),
long_m_center = mean(lon),
named_cluster100 = first(named_cluster100),
n = n())
saveRDS(df_cluster10_centroids, "./data/data_output/output_01c_df_cluster10_centroids.Rdata")
df_cluster100_centroids2 <- mutate(df_cluster100_centroids, FamilyID = "one")
df_joined_clusters <- left_join(df_cluster100_centroids2, df_cluster100_centroids2, by = "FamilyID", suffix=c(".A", ".B")) %>%
filter(named_cluster100.A != named_cluster100.B) %>%
rowwise %>%
mutate(name = toString(sort(c(named_cluster100.A, named_cluster100.B)))) %>%
distinct(name, .keep_all=T) %>%
mutate(distance = sqrt((long_m_center.A - long_m_center.B)^2+(lat_m_center.A - lat_m_center.B)^2))
saveRDS(df_joined_clusters, "./data/data_output/output_01c_df_cluster100_pw_distances.Rdata")
##%######################################################%##
#                                                          #
####             PREPARING FILES FOR COLONY             ####
#                                                          #
##%######################################################%##
# Purpose: This script is used to take the output of 01d (merged genotype file) and prepare various inputs for COLONY.
# We need an ERR file and a GENO file. We then paste those together to make the DAT file.
# PACKAGES ----------------------------------------------------------------
library(tidyverse)
# DATA ---------------------------------------------------------------------
#Genotype data
df_rpbb_fulldata <- readRDS("./data/data_output/output_01d_merged_genotypes.Rdata")
#Error rate data of kept loci
df_error_rates <- readRDS("./data/data_output/output_01d_error_rates.Rdata")
#Helper vector with names of loci
v_loci_kept <- readRDS("./data/data_output/output_01d_vector_good_loci.Rdata")
# COMMON FILTERS FOR ALL GENO SETS ----------------------------------------
# filter out individuals with less than 10 markers, females, only individuals not from known nests
df_rpbb_female_geno <- df_rpbb_fulldata %>%
filter(loci_w_data >= 10,
#NOTE that this is ONLY females in this dataset now!!
sex == "female",
#NOTE excluding individuals from known nests! I believe this helps COLONY's assumptions
is.na(which_nest))
# GENOTYPE FILES FROM EACH CROSS OF CLUSTER X YEAR ------------------------
# saving the grouped dataframe for use in group_split (it's a little silly but whatever)
df_grp_clst_yr <- df_rpbb_female_geno %>%
group_by(named_cluster100, year)
# group splitting the dataframe by the groups defined above, creates a list of separate dfs for each group
list_clst_year <- group_split(df_grp_clst_yr)
#group_keys(df_grp_clst_yr)
# getting the "group keys" with count of group membership, creating a helper column for easy filtering and whatnot
df_groups_key <- df_grp_clst_yr %>% count() %>% mutate(clst_yr = str_replace(paste0(named_cluster100,"_",year), pattern = " ", "_"))
#saving this as a helper to match in later steps
df_keys_match <- df_groups_key %>%
rowid_to_column("rowid") %>%
mutate(rowid = as.character(rowid))
#save the helper!
saveRDS(df_keys_match, file = "./analyses/inputs_colony/02a01_rpbb_batch_group_keys.Rdata")
# taking the list of dfs and selecting only the internal barcode and loci data, replacing NAs with 0s for COLONY's rules
list_geno_clst_year <- map(list_clst_year, .f = list(. %>% dplyr::select(internal_barcode, all_of(v_loci_kept)) %>% mutate(across(v_loci_kept, ~replace_na(.x, 0)))))
##%######################################################%##
#                                                          #
####             PREPARING FILES FOR COLONY             ####
#                                                          #
##%######################################################%##
# Purpose: This script is used to take the output of 01d (merged genotype file) and prepare various inputs for COLONY.
# We need an ERR file and a GENO file. We then paste those together to make the DAT file.
# PACKAGES ----------------------------------------------------------------
library(tidyverse)
# DATA ---------------------------------------------------------------------
#Genotype data
df_rpbb_fulldata <- readRDS("./data/data_output/output_01d_merged_genotypes.Rdata")
#Error rate data of kept loci
df_error_rates <- readRDS("./data/data_output/output_01d_error_rates.Rdata")
#Helper vector with names of loci
v_loci_kept <- readRDS("./data/data_output/output_01d_vector_good_loci.Rdata")
# COMMON FILTERS FOR ALL GENO SETS ----------------------------------------
# filter out individuals with less than 10 markers, females, only individuals not from known nests
df_rpbb_female_geno <- df_rpbb_fulldata %>%
filter(loci_w_data >= 10,
#NOTE that this is ONLY females in this dataset now!!
sex == "female",
#NOTE excluding individuals from known nests! I believe this helps COLONY's assumptions
is.na(which_nest))
# GENOTYPE FILES FROM EACH CROSS OF CLUSTER X YEAR ------------------------
# saving the grouped dataframe for use in group_split (it's a little silly but whatever)
df_grp_clst_yr <- df_rpbb_female_geno %>%
group_by(named_cluster100, year)
# group splitting the dataframe by the groups defined above, creates a list of separate dfs for each group
list_clst_year <- group_split(df_grp_clst_yr)
#group_keys(df_grp_clst_yr)
# getting the "group keys" with count of group membership, creating a helper column for easy filtering and whatnot
df_groups_key <- df_grp_clst_yr %>% count() %>% mutate(clst_yr = str_replace(paste0(named_cluster100,"_",year), pattern = " ", "_"))
#saving this as a helper to match in later steps
df_keys_match <- df_groups_key %>%
rowid_to_column("rowid") %>%
mutate(rowid = as.character(rowid))
#save the helper!
saveRDS(df_keys_match, file = "./analyses/inputs_colony/02a01_rpbb_batch_group_keys.Rdata")
# taking the list of dfs and selecting only the internal barcode and loci data, replacing NAs with 0s for COLONY's rules
list_geno_clst_year <- map(list_clst_year, .f = list(. %>% dplyr::select(internal_barcode, all_of(v_loci_kept)) %>% mutate(across(v_loci_kept, ~replace_na(.x, 0)))))
##%######################################################%##
#                                                          #
####             PREPARING FILES FOR COLONY             ####
#                                                          #
##%######################################################%##
# Purpose: This script is used to take the output of 01d (merged genotype file) and prepare various inputs for COLONY.
# We need an ERR file and a GENO file. We then paste those together to make the DAT file.
# PACKAGES ----------------------------------------------------------------
library(tidyverse)
# DATA ---------------------------------------------------------------------
#Genotype data
df_rpbb_fulldata <- readRDS("./data/data_output/output_01d_merged_genotypes.Rdata")
#Error rate data of kept loci
df_error_rates <- readRDS("./data/data_output/output_01d_error_rates.Rdata")
#Helper vector with names of loci
v_loci_kept <- readRDS("./data/data_output/output_01d_vector_good_loci.Rdata")
# COMMON FILTERS FOR ALL GENO SETS ----------------------------------------
# filter out individuals with less than 10 markers, females, only individuals not from known nests
df_rpbb_female_geno <- df_rpbb_fulldata %>%
filter(loci_w_data >= 10,
#NOTE that this is ONLY females in this dataset now!!
sex == "female",
#NOTE excluding individuals from known nests! I believe this helps COLONY's assumptions
is.na(which_nest))
# GENOTYPE FILES FROM EACH CROSS OF CLUSTER X YEAR ------------------------
# saving the grouped dataframe for use in group_split (it's a little silly but whatever)
df_grp_clst_yr <- df_rpbb_female_geno %>%
group_by(named_cluster100, year)
# group splitting the dataframe by the groups defined above, creates a list of separate dfs for each group
list_clst_year <- group_split(df_grp_clst_yr)
#group_keys(df_grp_clst_yr)
# getting the "group keys" with count of group membership, creating a helper column for easy filtering and whatnot
df_groups_key <- df_grp_clst_yr %>% count() %>% mutate(clst_yr = str_replace(paste0(named_cluster100,"_",year), pattern = " ", "_"))
#saving this as a helper to match in later steps
df_keys_match <- df_groups_key %>%
rowid_to_column("rowid") %>%
mutate(rowid = as.character(rowid))
#save the helper!
saveRDS(df_keys_match, file = "./analyses/inputs_colony/02a01_rpbb_batch_group_keys.Rdata")
list_geno_clst_year <- map(list_clst_year, .f = list(. %>% dplyr::select(internal_barcode, all_of(v_loci_kept)) %>% mutate(across(v_loci_kept, ~replace_na(.x, 0)))))
colony_header <- read_file("./analyses/inputs_colony/header_files/colony_header_partial.txt")
list_group_keys <- df_groups_key %>%
mutate(header_top = paste(clst_yr, clst_yr, n, colony_header, sep = "\n")) %>%
ungroup() %>%
# dplyr::select(header_top) %>%
split(.$clst_yr) %>%
map(., .f = list(. %>% dplyr::select(header_top)))
# save it all as header files to a folder...no touch folder!!
mapply(function (x,y) write_tsv(x, file = paste0('./analyses/inputs_colony/header_files/batch_rpbb/', y, '.txt'), col_names = FALSE), list_group_keys, paste0(names(list_group_keys),"_header"))
df_rpbb_err <- df_error_rates %>%
#pivot existing error rate data to wide format so all loci are the column names with their error rate as only value
pivot_wider(names_from = locus, values_from = error_rate) %>%
# add two dummy rows of NAs
add_row(.before = 1) %>%
add_row(.before = 1) %>%
# replace NAs with 0s to satisfy COLONY criteria
replace(is.na(.), 0)
write_tsv(df_rpbb_err, file = "./analyses/inputs_colony/err_files/output_02a_rpbb_err.txt", col_names = TRUE)
err_rates <- read_file("./analyses/inputs_colony/err_files/output_02a_rpbb_err.txt")
mapply(function (x,y) write_tsv(x, file = paste0('./analyses/inputs_colony/geno_files/batch_rpbb/', y, '.txt'), col_names = FALSE), list_geno_clst_year, paste0(names(list_group_keys),"_geno"))
v_genofiles <- list.files("./analyses/inputs_colony/geno_files/batch_rpbb/", full.names = TRUE)
v_headerfiles <- list.files("./analyses/inputs_colony/header_files/batch_rpbb/", full.names = TRUE)
df_files <- data_frame(cat = "cat", header = v_headerfiles, error = "./analyses/inputs_colony/err_files/output_02a_rpbb_err.txt", geno = v_genofiles, footer = "./analyses/inputs_colony/header_files/colony_footer.txt", pipe = "> ./analyses/inputs_colony/DAT_files/batch_rpbb/", cluster = df_groups_key$clst_yr) %>%
mutate(sysstring = paste(cat, header, error, geno, footer, paste0(pipe, cluster,".DAT")))
for (x in 1:nrow(df_files)) {
system(df_files$sysstring[x])
}
v_datfiles <- list.files("./analyses/inputs_colony/DAT_files/batch_rpbb/", full.names = TRUE)
df_helper <- data_frame(batch = df_groups_key$clst_yr,
begin = "~/Colony2_Mac_01_02_2022/run_colony.out",
middle1 = "IFN:../../../.",
middle2 = v_datfiles,
# this last part is a music file in my Downloads folder that I play to let me know the script is done running; change it or download a song into your Downloads folder named Dry Town I guess!
end =  " ; afplay ~/Downloads/Dry\ Town.mp3") %>%
mutate(colcommand = paste(begin, paste0(middle1, middle2), end))
write_csv(df_helper, "./analyses/inputs_colony/rpbb_batch_jan_2023_helper_list.csv")
##%######################################################%##
#                                                          #
####             SPATIAL DATA CLUSTERING OF             ####
####            POINTS TO ASSIGN POPULATIONS            ####
#                                                          #
##%######################################################%##
#PURPOSE - to take the metadata with lat-long and assign them to clusters based on some threshold rule of distance. This seems preferable to assigning to population based on some more arbitrary metric (like county or just...my decision)
### This code largely follows the StackOverflow page here: https://gis.stackexchange.com/questions/17638/clustering-spatial-data-in-r
# PACKAGES ----------------------------------------------------------------
library(tidyverse)
library(sp)
library(sf)
library(maps)
library(rgdal)
library(geosphere)
library(janitor)
library(plotly)
# DATA --------------------------------------------------------------------
df_meta <- readRDS("./data/data_output/output_01b_df_rpbb_metadata.Rdata")
# CONVERT METADATA FRAME INTO A SPATIAL DATA FRAME ------------------------
df_meta2=rename(df_meta, x=longitude,y=latitude) %>%
#This next filtering step no longer does anything because there are no longer specimens lacking lat-long data...but I am afraid to change it.
filter(!is.na(x))
# Transforming into UTM -----
geo_meta <- st_as_sf(df_meta2, coords = c("x", "y"), crs = 4326)
geo_meta2<-st_transform(x = geo_meta, crs = 32616)
geo_meta2$lon<-st_coordinates(geo_meta2)[,1] # get coordinates
geo_meta2$lat<-st_coordinates(geo_meta2)[,2] # get coordinates
# use the st_distance function to generate a geodesic distance matrix in meters
mtx_distance <- st_distance(geo_meta2, geo_meta2)
# cluster all points using a hierarchical clustering approach
hc <- hclust(as.dist(mtx_distance), method="complete")
# define multiple distance thresholds
d05 = 5000
d10 = 10000
d25 = 25000
d50 = 50000
d100 = 100000
# define clusters based on a tree "height" cutoff "d" and add them to the SpDataFrame
# geo_meta$cluster <- cutree(hc, h=d)
geo_meta2$cluster05 <- cutree(hc, h=d05)
geo_meta2$cluster10 <- cutree(hc, h=d10)
geo_meta2$cluster25 <- cutree(hc, h=d25)
geo_meta2$cluster50 <- cutree(hc, h=d50)
geo_meta2$cluster100 <- cutree(hc, h=d100)
#changed this to multiple thresholds on 2022-12-15
df_geo <-st_set_geometry(geo_meta2, NULL) %>%
inner_join(., df_meta) %>%
add_count(cluster05, name = "n_cluster05") %>%
add_count(cluster10, name = "n_cluster10") %>%
add_count(cluster25, name = "n_cluster25") %>%
add_count(cluster50, name = "n_cluster50") %>%
add_count(cluster100, name = "n_cluster100")
df_geo_named <- df_geo %>%
mutate(named_cluster100 = case_when(
cluster100 == 1 ~ "Appalachian",
cluster100 == 2 ~ "Iowa City",
cluster100 == 3 ~ "Quad Cities",
cluster100 == 4 ~ "Decorah",
cluster100 == 5 ~ "Twin Cities",
cluster100 == 6 ~ "SE Minnesota",
cluster100 == 7 ~ "Milwaukee",
cluster100 == 8 ~ "Madison",
cluster100 == 9 ~ "North Illinois",
cluster100 == 10 ~ "Chicago",
cluster100 == 11 ~ "North Milwaukee",
cluster100 == 12 ~ "Green Bay",
cluster100 == 13 ~ "Central Wisconsin"
))
# EXPORT RESULT -----------------------------------------------------------
saveRDS(df_geo_named, "./data/data_output/output_01c_df_rpbb_clustered.Rdata")
# FINDING CENTROIDS OF CLUSTERS -------------------------------------------
df_cluster100_centroids <- df_geo_named %>%
group_by(named_cluster100) %>%
summarise(latitude_center = mean(latitude),
longitude_center = mean(longitude),
lat_m_center = mean(lat),
long_m_center = mean(lon))
saveRDS(df_cluster100_centroids, "./data/data_output/output_01c_df_cluster100_centroids.Rdata")
# FINDING CENTROIDS OF SITE (10KM LEVEL) CLUSTERS -------------------------------------------
#!!!!!!!!!WARNING!!!!!!!!!!! - this will break if colonizer from step 02c not loaded, done out of order...So, it's a bit annoying, but you'll need to run 01d, 02a, COLONY, etc before running these subsequent steps. (Source ensures the output of 02c are actually in your environment, not just previously run)
source("./analyses/02a01_preparing_colony_inputs.R")
##%######################################################%##
#                                                          #
####             WRANGLING OUTPUT OF COLONY             ####
#                                                          #
##%######################################################%##
#PURPOSE - this script is to take the output of COLONY, filter out "bad" families, do some merging with the original metadata file, and otherwise "wrangle" the information to be usable for downstream analysis
# PACKAGES ----------------------------------------------------------------
library(tidyverse)
library(janitor)
# DATA --------------------------------------------------------------------
# group keys helper, needed for easy matching back to the long df of best clusters
df_keys_match <- readRDS("./analyses/inputs_colony/02a01_rpbb_batch_group_keys.Rdata")
# pull all over the bestclusters from COLONY outputs...make a list of file paths, then load all of them, bind them together with a key, join that key to the group keys, janitor
list_path_bcs = list.files(path = "analyses/outputs_colony/batch_rpbb/", pattern="*.BestCluster", recursive = TRUE, full.names = TRUE)
df_bcs = lapply(list_path_bcs, read_table, col_names = TRUE) %>% bind_rows(.id = "rowid") %>% inner_join(., df_keys_match) %>% clean_names()
# Metadata from the 01d step; we may need the genotype data when loading into future steps, so keep it all connected
df_md <- readRDS("data/data_output/output_01d_merged_genotypes.Rdata")
# Name the output file for below
pn_batch = "rpbb_batch_colonizeR"
# Output directory for the final csv
od = "analyses/outputs_colony/r_colonizer/"
#ONLY KEEP families with a probability equal to/greater than 80% -- might want to make this more stringent later!!
fam_threshold <- 0.8
df_flt_batch <- df_bcs %>%  mutate(family_index = if_else(probability < fam_threshold, 1000+row_number(), cluster_index),
family_index = paste0(family_index, "_", clst_yr))
# Run the function
colonizeR<-function(bestCluster, metadat, projectName, outdir)
{
require(tidyverse)
# Trim BestCluster
bestC = bestCluster %>%
select(family_index, offspring_id)
# Join, remove individuals absent in BestCluster, create FamilyID column, remove extra variables
dat_full <- inner_join(metadat, bestC, by=c("internal_barcode"="offspring_id"))  %>%
arrange(family_index) %>%
mutate(occur = !family_index %in% family_index[duplicated(family_index)]
) %>%
mutate(family_id = if_else(occur == TRUE, "s", as.character(family_index))) #%>%
#select(-occur,-gps.ID,-Library.ID,-unique.ID.old,-plate,-occur,-plate.ID)
## Save the dataframe
write_csv(dat_full, file = paste0(outdir,projectName,".csv"), col_names = TRUE)
}
# Run it with objects defined above (change names if desired)
colonizeR(df_flt_batch,df_md,pn_batch,od)
df_batch_colonizer <- read_csv("./analyses/outputs_colony/r_colonizer/rpbb_batch_colonizeR.csv")
df_rpbb_keepers <- df_batch_colonizer %>%
group_by(family_index) %>%
sample_n(1)
v_rpbb_keepers <- df_rpbb_keepers %>% pull(internal_barcode)
saveRDS(v_rpbb_keepers, file = "./analyses/outputs_colony/r_colonizer/02c_v_rpbb_keepers.Rdata")
df_cluster10_centroids <- df_batch_colonizer %>%
group_by(cluster10, year) %>%
summarise(latitude_center = mean(latitude),
longitude_center = mean(longitude),
lat_m_center = mean(lat),
long_m_center = mean(lon),
named_cluster100 = first(named_cluster100),
n = n())
#sometimes the source will give a
source("./analyses/02a01_preparing_colony_inputs.R")
source("./analyses/02c01_batch_colonizeR.R")
df_cluster10_centroids <- df_batch_colonizer %>%
group_by(cluster10, year) %>%
summarise(latitude_center = mean(latitude),
longitude_center = mean(longitude),
lat_m_center = mean(lat),
long_m_center = mean(lon),
named_cluster100 = first(named_cluster100),
n = n())
saveRDS(df_cluster10_centroids, "./data/data_output/output_01c_df_cluster10_centroids.Rdata")
df_cluster100_centroids2 <- mutate(df_cluster100_centroids, FamilyID = "one")
df_joined_clusters <- left_join(df_cluster100_centroids2, df_cluster100_centroids2, by = "FamilyID", suffix=c(".A", ".B")) %>%
filter(named_cluster100.A != named_cluster100.B) %>%
rowwise %>%
mutate(name = toString(sort(c(named_cluster100.A, named_cluster100.B)))) %>%
distinct(name, .keep_all=T) %>%
mutate(distance = sqrt((long_m_center.A - long_m_center.B)^2+(lat_m_center.A - lat_m_center.B)^2))
saveRDS(df_joined_clusters, "./data/data_output/output_01c_df_cluster100_pw_distances.Rdata")
library(tidyverse)
library(janitor)
library(adegenet)
library(poppr)
library(hierfstat)
library(reshape2)
df_rpbb_colonizer <- read_csv("./analyses/outputs_colony/r_colonizer/rpbb_batch_colonizeR.csv")
v_rpbb_keepers <- readRDS("./analyses/outputs_colony/r_colonizer/02c_v_rpbb_keepers.Rdata")
v_loci_kept <- readRDS("./data/data_output/output_01d_vector_good_loci.Rdata")
v_loci_kept <- readRDS("./data/data_output/output_01d_vector_good_loci.Rdata")
# select only the individual shortnames, sites, and genotypes from the dataframe
df_rpbb_simple <- df_rpbb_colonizer %>%
dplyr::select(internal_barcode, named_cluster100, all_of(v_loci_kept)) %>%
# !!!!!!!! THIS IS WHERE THE REMOVAL OF SIBLINGS HAPPENS!!!!!!!!
filter(internal_barcode %in% v_rpbb_keepers)
# create vector of individual IDs
v_rpbb_shortnames <- pull(df_rpbb_simple, internal_barcode)
# create vector of site names
v_rpbb_sites <- pull(df_rpbb_simple, named_cluster100)
# remove shortname, site names, then combine adjacent columns to get each allele into a single cell, last a little ditty to remove the "_1" in the merged columns
df_rpbb_onlyGeno <- df_rpbb_simple %>%
dplyr::select(-internal_barcode, -named_cluster100)
df_rpbb_mergeGenos <- mapply(function(x, y) {
paste(x, y, sep = ",")},
df_rpbb_onlyGeno[ ,seq(1, ncol(df_rpbb_onlyGeno), by = 2)],
df_rpbb_onlyGeno[ ,seq(2, ncol(df_rpbb_onlyGeno), by = 2)])
colnames(df_rpbb_mergeGenos) <- gsub(x = colnames(df_rpbb_mergeGenos), pattern = "_1", replacement = "", fixed = TRUE)
df_rpbb_alleles <- as.data.frame(df_rpbb_mergeGenos) %>%
mutate_all(funs(str_replace_all(., "NA,NA", NA_character_)))
gen_rpbb = df2genind(df_rpbb_alleles, ploidy = 2, ind.names = v_rpbb_shortnames, pop = v_rpbb_sites, sep = ",")
saveRDS(gen_rpbb, "./analyses/analyses_output/03a_rpbb_femaleNOknown_NOSibs_genind.Rdata")
